default-provider = "openai"

[llm-provider.google]
model = "gemini-1.5-pro"
api_key = "your-api-key"

[llm-provider.ollama]
base_url = "http://localhost:11434/api/chat"
model = "llama3"

# Supports both OpenAI and Deepinfra
[llm-provider.openai]
base_url = "https://api.deepinfra.com/v1/openai/chat/completions"
model = "google/gemma-2-27b-it"
api_key = "your-api-key"

