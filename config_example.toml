default-provider = "ollama"

[llm-provider]
  [llm-provider.google]
    base_url = "No need to fill in"
    model = "gemini-1.5-flash"
    api_key = "YOUR_API_KEY"
  [llm-provider.ollama]
    base_url = "http://localhost:11434/api/chat"
    model = "llama3"
    api_key = ""
  [llm-provider.openai]
    base_url = "https://api.deepinfra.com/v1/openai/chat/completions"
    model = "google/gemma-2-27b-it"
    api_key = "YOUR_API_KEY"
